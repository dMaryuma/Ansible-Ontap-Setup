## This is the main Vars file for configuring cluster ##

cluster_name: cluster1
cluster_ip: "192.168.0.101"
netmask: "255.255.255.0"
username: "admin"
password: "Netapp1!"
https_global: "true"
validate_certs_global: "false"
domain: "demo.netapp.com"

hosts:
  node1:
    name: "cluster1-01"
    mgmt_ip: "192.168.0.111"
    subnet: "255.255.255.0"
    gateway: "192.168.0.1"
  node2:
    name: "cluster1-02"
    mgmt_ip: "192.168.0.112"
    subnet: "255.255.255.0"
    gateway: "192.168.0.1"
    cluster:
      private_ip: 169.254.10.11   # DO NOT CHANGE
      netmask: 255.255.0.0        # DO NOT CHANGE
      home_port: e0a

licenses: # Add license protocol
  - XXXXXXXXXXXXXXXXXXXXXXXXXXXX 
  - XXXXXXXXXXXXXXXXXXXXXXXXXXXX

motd: "Welcome to XXXXX Storage System. This is a monitored system! "

aggregates:
  - { node: "{{ hosts['node1'].name }}", name: "cluster1_01_SSD_1", diskcount: "10", disktype: "SSD", raidsize: "28", raidtype: "raid_dp", hybrid: true, allocationunits: "4", sp_raid: "raid_dp"}
  - { node: "{{ hosts['node2'].name }}", name: "cluster1_01_SSD_1", diskcount: "10", disktype: "SSD", raidsize: "28", raidtype: "raid_dp", hybrid: false}

storagepool:
  - { nodes: "{{ hosts['node1'].name }}", sp: "SP1", diskcount: "6", disksize: "800GB"}

vservers:
  - { name: svm1, language: en_us, protocols: "iscsi"}
  - { name: svm2, language: he, protocols: "nfs"}

exportrules:
  - { name: EP1, client_match: x.x.x.0/24, vserver: svm1 }
  - { name: EP2, client_match: x.x.x.0/24, vserver: svm1 }

igroup:
  - { name: ig1, initiator_group_type: iscsi, os_type: linux, initiator_names: "iqn.1995-08.com.example:string,iqn.1995-08.com.example:abcd.com", vserver: svm1}
  - { name: ig2, initiator_group_type: iscsi, os_type: linux, initiator_names: "iqn.1995-08.com.example:string", vserver: svm1}  

volumes:
  - { name: vol2, aggr: "{{ aggregates[0].name }}", size: 10, policy: default, junction_path: "/vol2", snappercent: 3, vserver: svm1, securitystyle: unix, snapshot_policy: default, sis_enable: true}
  - { name: vol3, aggr: "{{ aggregates[0].name }}", size: 10, policy: default, junction_path: "/vol3", snappercent: 3, vserver: svm1, securitystyle: unix, snapshot_policy: default, sis_enable: false}

FGvolumes:
  - { name: vol1_fg, aggr_list: "{{ aggregates[0].name }}", size: 10, policy: default, snappercent: 3, vserver: svm1, securitystyle: unix, aggr_list_multiplier: "2", snapshot_policy: default, sis_enable: true } # Felxgroup

luns:
  - { name: lun1, vserver: svm1, flexvol_name: "{{ volumes[0].name }}", size: 1, os_type: linux, space_reserve: true, space_allocation: true, igroup: ig1, lun_id: 0}
  - { name: lun2, vserver: svm1, flexvol_name: "{{ volumes[0].name }}", size: 1, os_type: linux, space_reserve: true, space_allocation: true, igroup: ig1, lun_id: 2}
  
dns:
  - { dns_domains: "{{ domain }}", dns_nameservers: y.y.y.y, vserver: "{{ cluster_name }}"}
  - { dns_domains: "{{ domain }}", dns_nameservers: y.y.y.y, vserver: svm1}
  - { dns_domains: "{{ domain }}", dns_nameservers: y.y.y.y, vserver: svm2}

ntp:
  - { server_name: "x.x.x.x", version: auto }

snapshot_policy:
  - { name: snap_policy1, schedule: "hourly,weekly", count: "2,3", snapmirror_label: ""} # The schedule list is corresponding to count. means hourly-2 ; weekly-3

ports:
  - { node: "{{ hosts['node1'].name }}", port: e0c, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node1'].name }}", port: e0d, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node1'].name }}", port: e0e, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node1'].name }}", port: e0f, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node2'].name }}", port: e0c, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node2'].name }}", port: e0d, mtu: 9000 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node2'].name }}", port: e0e, mtu: 1500 , flowcontrol: none, autonegotiate: true}
  - { node: "{{ hosts['node2'].name }}", port: e0f, mtu: 1500 , flowcontrol: none, autonegotiate: true}

ifgrps:
  - { name: a0a, node: "{{ hosts['node1'].name }}", ports: "e0c,e0e", mode: multimode_lacp, mtu: 9000, distribution_function: ip }
  - { name: a0a, node: "{{ hosts['node2'].name }}", ports: "e0c,e0e", mode: multimode_lacp, mtu: 9000, distribution_function: ip }
  - { name: a0b, node: "{{ hosts['node1'].name }}", ports: "e0d,e0f", mode: multimode_lacp, mtu: 1500, distribution_function: ip }
  - { name: a0b, node: "{{ hosts['node2'].name }}", ports: "e0d,e0f", mode: multimode_lacp, mtu: 1500, distribution_function: ip }


vlans:
  - { vlanid: 300, node: "{{ hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 400, node: "{{ hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 62, node: "{{ hosts['node1'].name }}", phy_interface: "a0a" }
  - { vlanid: 300, node: "{{ hosts['node2'].name }}", phy_interface: "a0a" }
  - { vlanid: 400, node: "{{ hosts['node2'].name }}", phy_interface: "a0a" }
  - { vlanid: 62, node: "{{ hosts['node2'].name }}", phy_interface: "a0a" }

bcasts:
  - { name: vlan_400, ports: "{{hosts['node1'].name }}:a0a-400,{{hosts['node2'].name }}:a0a-400", mtu: 1500 }
  - { name: vlan_300, ports: "{{hosts['node1'].name }}:a0a-300,{{hosts['node2'].name }}:a0a-300", mtu: 1500 }

lifs:
  - { name: lif1, node: "{{ hosts['node1'].name }}", port: e0c, address: 192.168.0.230, netmask: 255.255.255.0, vserver: svm2, protocols: "nfs,cifs", dns_domain_name: "demo.netapp.com" }
  - { name: lif2, node: "{{ hosts['node2'].name }}", port: e0c, address: 192.168.0.231, netmask: 255.255.255.0, vserver: svm1, protocols: "nfs,cifs"}
  - { name: lif1, node: "{{ hosts['node2'].name }}", port: e0c, address: 192.168.0.232, netmask: 255.255.255.0, vserver: svm2, protocols: "nfs,cifs"}

routes: 
  - { vserver: "{{ cluster_name }}", destination: 0.0.0.0/0, gateway: x.x.x.254 }
  - { vserver: SVM_Beci, destination: 0.0.0.0/0, gateway: x.x.x.254 }
  - { vserver: SVM_David, destination: 0.0.0.0/0, gateway: y.y.y.254 }

cifsad: # Join vserver to domain for cifs service
 - { vserver: svm2, cifs_server_name: svm2_cifs, domain: "{{ domain }}", admin_user: "administrator",admin_password: "Netapp1!", force: true }

cifsShares:
  - { share_name: share1, vol_path: "/vol2", vserver: svm1, share_properties: "browsable,oplocks,changenotify,show_previous_versions", symlink_properties: "enable" }
  - { share_name: share2, vol_path: "/vol3", vserver: svm1, share_properties: "browsable,oplocks,changenotify,show_previous_versions", symlink_properties: "enable" }

nfs: 
  - { vserver: svm1, nfsv3: enabled, nfsv4: enabled, nfsv41: enabled, vstorage: enabled }
  - { vserver: svm1, nfsv3: enabled, nfsv4: enabled, nfsv41: enabled, vstorage: enabled }

iscsi:
  - { vserver: svm1}
sp:
  - { node: "{{ hosts['node1'].name }}", dhcp: none, ip_enabled: true, address_type: ipv4, state: present, ip_address: x.x.x.x, netmask: 255.255.255.0, gateway: x.x.x.x }
  - { node: "{{ hosts['node2'].name }}", dhcp: none, ip_enabled: true, address_type: ipv4, state: present, ip_address: x.x.x.x, netmask: 255.255.255.0, gateway: x.x.x.x }

snmp:
  - { community_name: ansible_snmp, access_control: ro }

loginUsers:
  - { username: "vsadmin", password: "8LetterLength", apps: "http,ontapi,ssh", role: "vsadmin", vserver: "svm1"} # Enable vsadmin
  - { username: "test1", password: "8LetterLength", apps: "http", role: "readonly", vserver: "svm1"}
  - { username: "test2", password: "8LetterLength", apps: "http,ssh", role: "vsadmin", vserver: "svm1"}
